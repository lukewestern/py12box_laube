{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process AGAGE JFJ and CGO data for Johannes' gases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user/home/lw13938/work/py12box_agage/py12box_agage/agage_process.py:39: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
      "  if site is not \"CGO\":\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from py12box_invert import utils\n",
    "from pathlib import Path\n",
    "from py12box_agage import agage_process \n",
    "import getpass\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "species = \"CFC-115\" #, -115, and -114\n",
    "output_directory=None\n",
    "repeatability=0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/gcms/monthly_data/JFJ-medusa.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/gcms/monthly_data/MHD-medusa.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/ale_gage_agage/monthly_data/MHD-agA.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/gcms/monthly_data/THD-medusa.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/ale_gage_agage/monthly_data/THD-agA.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/gcms/monthly_data/SMO-medusa.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/ale_gage_agage/monthly_data/SMO-agA.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/gcms/monthly_data/CGO-medusa.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_GATech/ale_gage_agage/monthly_data/CGO-agA.mon\n",
      "Reading /user/home/lw13938/shared/obs_raw/AGAGE_archive/output/CFC115/CFC115_archive_nonan.csv\n"
     ]
    }
   ],
   "source": [
    "if species != \"CFC-115\":\n",
    "    sites =  {\"JFJ\":0, \"MHD\":0, \"THD\":0, \"RPB\":1, \"SMO\":2, \"CGO\":3}\n",
    "else:\n",
    "    sites =  {\"JFJ\":0, \"MHD\":0, \"THD\":0, \"SMO\":2, \"CGO\":3}\n",
    "\n",
    "# Check if species is in data selector\n",
    "data_selector = pd.read_csv(\"/user/home/lw13938/work/py12box_agage/py12box_agage/agage_data_selector.csv\",\n",
    "                            index_col=\"Species\")\n",
    "    \n",
    "if species not in data_selector.index:\n",
    "    print(f\"Exiting: {species} not in agage_data_selector.csv\")\n",
    "\n",
    "\n",
    "# Array of sites and 12-box model box numbers\n",
    "species_in = species\n",
    "\n",
    "dfs = []\n",
    "rmsite = []\n",
    "comment_string = f\"# AGAGE data for {species}\\n\"\n",
    "comment_string += f\"# Created by {getpass.getuser()} on {datetime.now()}\\n\"\n",
    "comment_string += f\"# Contact AGAGE data owners before use \\n\"\n",
    "comment_string += f\"# This file contains data from the following sites/instruments: \\n\"\n",
    "comment_string += \"#===================================================\\n\"\n",
    "\n",
    "for site in sites.keys():\n",
    "    \n",
    "    df_site, comment_site = agage_process.combine_instruments(species, site)\n",
    "\n",
    "    if df_site is not None:\n",
    "        dfs.append(df_site)\n",
    "        comment_string += comment_site\n",
    "    else:\n",
    "        rmsite = rmsite + [site]\n",
    "\n",
    "for rms in rmsite:\n",
    "    sites.pop(rms)\n",
    "\n",
    "if len(dfs) == 0:\n",
    "    print(\"No data found\")\n",
    "\n",
    "for bi in range(4):\n",
    "    if bi not in sites.values():\n",
    "        df_empty = dfs[0].copy() #\n",
    "        df_empty.loc[:] = np.nan\n",
    "        dfs.append(df_empty)\n",
    "        sites[f\"XX{bi}\"] = bi\n",
    "\n",
    "# Find units\n",
    "units = [df.xs(\"mf\", level=\"var\", axis=1).columns.get_level_values(\"unit\").values[0] for df in dfs]\n",
    "if len(set(units)) != 1:\n",
    "    raise(f\"ERROR: Units don't match: {units}\")\n",
    "\n",
    "# Find scales\n",
    "scales = [df.xs(\"mf\", level=\"var\", axis=1).columns.get_level_values(\"scale\").values[0] for df in dfs]\n",
    "if len(set(scales)) != 1:\n",
    "    raise(f\"ERROR: Units don't match: {scales}\")\n",
    "\n",
    "# Concatenate and average numeric data\n",
    "df_concat = pd.concat([df.xs(units[0], level=\"unit\", axis=1) for df in dfs], \n",
    "                      axis=1, keys=[(site, box) for site, box in sites.items()], names=[\"site\", \"box\"])\n",
    "df_grouped = df_concat.groupby(by=[\"var\", \"box\", \"scale\"], axis=1).mean()\n",
    "\n",
    "# Drop scale level\n",
    "df_grouped = df_grouped.droplevel(\"scale\", axis=1)\n",
    "\n",
    "# Collect instrument data\n",
    "df_instrument_concat = pd.concat([df.xs(\"instrument\", level=\"var\", axis=1) for df in dfs], \n",
    "                                  axis=1, keys=[(site, box) for site, box in sites.items()], names=[\"site\", \"box\"])\n",
    "\n",
    "\n",
    "instrument_list = pd.DataFrame(\n",
    "                         columns=pd.MultiIndex.from_tuples(((\"instruments\", 0),\n",
    "                                                            (\"instruments\", 1),\n",
    "                                                            (\"instruments\", 2),\n",
    "                                                            (\"instruments\", 3)), names=[\"var\", \"box\"]),\n",
    "                         index=df_grouped.index)#, dtype=pd.StringDtype())\n",
    "\n",
    "for bi in range(4):\n",
    "    df_instrument_concat_bi = df_instrument_concat.xs(bi, level=\"box\", axis=1)\n",
    "    instrument_list.iloc[:, bi] = df_instrument_concat_bi.iloc[:, 0]\n",
    "    for sitei in range(len(df_instrument_concat_bi.columns))[1:]:\n",
    "        instrument_list.iloc[:, bi] = instrument_list.iloc[:, bi].str.cat(df_instrument_concat_bi.iloc[:,sitei],\n",
    "                                                                            sep=\"|\",\n",
    "                                                                            na_rep=\"\")\n",
    "\n",
    "# Collect sites\n",
    "site_list = pd.DataFrame(\n",
    "                         columns=pd.MultiIndex.from_tuples(((\"sites\", 0),\n",
    "                                                            (\"sites\", 1),\n",
    "                                                            (\"sites\", 2),\n",
    "                                                            (\"sites\", 3)), names=[\"var\", \"box\"]),\n",
    "                         index=df_grouped.index)#, dtype=pd.StringDtype())\n",
    "\n",
    "for i in df_concat.index:\n",
    "    dfi = df_concat.loc[i].dropna()\n",
    "    if len(dfi) == 0:\n",
    "        site_list.loc[i] = [\"\", \"\", \"\", \"\"]\n",
    "    else:\n",
    "        site_row = []\n",
    "        for bi in range(4):\n",
    "            if bi in dfi.index.get_level_values(\"box\"):\n",
    "                site_set = set(dfi.xs(bi, level=\"box\").index.get_level_values(\"site\"))\n",
    "                if len(site_set) == 0:\n",
    "                    site_row.append(\"\")\n",
    "                else:\n",
    "                    site_row.append(\"|\".join(site_set))\n",
    "            else:\n",
    "                site_row.append(\"\")\n",
    "        site_list.loc[i] = site_row\n",
    "\n",
    "# Put measurements, sites and instruments together into one dataframe\n",
    "df_grouped = pd.concat([df_grouped, site_list, instrument_list], axis=1)\n",
    "\n",
    "# Modify uncertainties\n",
    "#  at this stage, uncertainties are either standard deviations of repeat samples (archive) or variability (AGAGE)\n",
    "############################################\n",
    "\n",
    "# For archive data, add representation error\n",
    "for bi in range(4):\n",
    "\n",
    "    if bi==0 or bi == 1 or bi == 2:\n",
    "        continue\n",
    "\n",
    "    df_variability = df_grouped[(\"mf_variability\", bi)].copy()\n",
    "\n",
    "    wh_archive = df_grouped[(\"instruments\", bi)].str.contains(\"Archive\", na=False)\n",
    "    wh_insitu = np.isfinite(df_variability) & ~wh_archive\n",
    "\n",
    "    mf_insitu_av = (df_variability[wh_insitu]).mean()\n",
    "    mf_insitu_variability_av = (df_variability[wh_insitu]).mean()\n",
    "\n",
    "    df_variability[wh_archive] = \\\n",
    "        np.sqrt(df_variability[wh_archive]**2 + \\\n",
    "            (df_variability[wh_archive] / mf_insitu_av * mf_insitu_variability_av)**2)\n",
    "\n",
    "    df_grouped[(\"mf_variability\", bi)] = df_variability.copy()\n",
    "\n",
    "# Add a repeatability\n",
    "df_grouped[\"mf_variability\"] = np.sqrt(df_grouped[\"mf_variability\"]**2 + (df_grouped[\"mf\"]*repeatability)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append site and units\n",
    "comment_string += f\"# SCALE: {scales[0]}\\n# UNITS: {units[0]}\\n\"\n",
    "\n",
    "# If no output directory given, default to data folder\n",
    "if not output_directory:\n",
    "    output_directory = f\"/user/home/lw13938/work/py12box_laube/data_allagage/{species}/inputs/\"\n",
    "# If output directories don't exist, create them\n",
    "if not Path(output_directory).exists():\n",
    "    if not Path(output_directory).parent.exists():\n",
    "        print(f\"... creating directory {Path(output_directory).parent}\")\n",
    "        Path(output_directory).parent.mkdir()\n",
    "    print(f\"... creating directory {output_directory}\")\n",
    "    Path(output_directory).mkdir()\n",
    "    \n",
    "with open(Path(output_directory) / f\"{species}_obs_agage.csv\", 'w') as fout:\n",
    "    fout.write(comment_string)\n",
    "    df_grouped.to_csv(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Archive'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32444946df3d1f09fa25414f670079740b7e2d0c25afd0120eb4553ca7acfe0d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 ('acrg-dev': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
