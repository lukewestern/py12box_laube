{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dcd3b97",
   "metadata": {},
   "source": [
    "#Â Process UEA/FZJ H-1202 values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "189d1ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from py12box_invert.utils import decimal_to_pandas\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import getpass\n",
    "from datetime import datetime\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4b42ac14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_h1202():\n",
    "        \"\"\"\n",
    "        Read the H1202 data from the CGO site and return a DataFrame with the data\n",
    "        \"\"\"\n",
    "        ueafn = \"/user/home/lw13938/work/py12box_laube/obs_raw/UEAFZJ/CGO_H1202.csv\"\n",
    "        df = pd.read_csv(ueafn, delimiter=',', encoding=\"utf-8\", skipinitialspace=True)\n",
    "\n",
    "        mf = df[\"H1202\"]\n",
    "        error = mf * 0.031\n",
    "\n",
    "        dfsp = pd.DataFrame(index=pd.to_datetime(decimal_to_pandas(df[\"Time\"].values)), \n",
    "                data={\"mf\":[float(f) for f in mf.values],\n",
    "                \"pmf\":[float(f) for f in error.values]})\n",
    "\n",
    "        return dfsp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3dccd0e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2009838/3302896542.py:17: FutureWarning: ChainedAssignmentError: behaviour will change in pandas 3.0!\n",
      "You are setting values through chained assignment. Currently this works in certain cases, but when using Copy-on-Write (which will become the default behaviour in pandas 3.0) this will never work to update the original DataFrame or Series, because the intermediate object on which we are setting values will behave as a copy.\n",
      "A typical example is when you are setting values in a column of a DataFrame, like:\n",
      "\n",
      "df[\"col\"][row_indexer] = value\n",
      "\n",
      "Use `df.loc[row_indexer, \"col\"] = values` instead, to perform the assignment in a single step and ensure this keeps updating the original `df`.\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "\n",
      "  df_monthly[\"mf_variability\"][np.where(df_monthly[\"mf_variability\"] == 0.0)[0]] = np.nanmean(df_monthly[\"mf_variability\"])\n",
      "/tmp/ipykernel_2009838/3302896542.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_monthly[\"mf_variability\"][np.where(df_monthly[\"mf_variability\"] == 0.0)[0]] = np.nanmean(df_monthly[\"mf_variability\"])\n",
      "/tmp/ipykernel_2009838/3302896542.py:17: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
      "  df_monthly[\"mf_variability\"][np.where(df_monthly[\"mf_variability\"] == 0.0)[0]] = np.nanmean(df_monthly[\"mf_variability\"])\n",
      "/tmp/ipykernel_2009838/3302896542.py:91: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  df_grouped = df_concat.groupby(by=[\"var\", \"box\", \"scale\"], axis=1).mean()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def laube_sites(species, site):\n",
    "    \"\"\"\n",
    "    Read Johanne's files and output in same format as \n",
    "    AGAGE Georgia Tech files.\n",
    "    \"\"\"\n",
    "    scale = \"UEA\"\n",
    "\n",
    "    df_v_site = get_h1202()\n",
    "\n",
    "\n",
    "    df_format = pd.DataFrame(data={\"var\":df_v_site.index.values,\"mf\":df_v_site.mf.values.astype(float), \"mf_variability\":df_v_site.pmf.values.astype(float), \"instrument\":[\"GCMS\",]*len(df_v_site.index.values)})\n",
    "    df_format = df_format.set_index(\"var\")\n",
    "    df_monthly = df_format.dropna().resample(\"MS\").mean(numeric_only =True)#.dropna()\n",
    "    intruments = [ \"GCMS\" if np.isfinite(item) else np.nan for item in df_monthly.mf ]\n",
    "    df_monthly.insert(2, \"instrument\", intruments, True)\n",
    "    species_columns = df_monthly.columns\n",
    "    df_monthly[\"mf_variability\"][np.where(df_monthly[\"mf_variability\"] == 0.0)[0]] = np.nanmean(df_monthly[\"mf_variability\"])\n",
    "    dfs = df_monthly[species_columns]    \n",
    "    \n",
    "    if dfs.empty:\n",
    "        return None, None        \n",
    "        \n",
    "    dfs.columns = pd.MultiIndex.from_tuples(((scale,\"ppt\", \"mf\"),\n",
    "                                            (scale,\"ppt\", f\"mf_variability\"),\n",
    "                                            (\"-\",\"-\", f\"instrument\")),\n",
    "                                            names=(\"scale\", \"unit\", \"var\"))\n",
    "    dfs.index.name = None\n",
    "    \n",
    "    comment_site = f'# {site} \\n#   1. GCMS\\n#------------------\\n'\n",
    "    return dfs,comment_site\n",
    "\n",
    "species_list = [\"H-1202\"]\n",
    "\n",
    "for species in species_list:\n",
    "    output_directory=None\n",
    "    repeatability=0.\n",
    "    sites = {\"CGO\":3}\n",
    "\n",
    "    # Check if species is in data selector\n",
    "    data_selector = pd.read_csv(\"/user/home/lw13938/work/py12box_agage/py12box_agage/agage_data_selector.csv\",\n",
    "                                index_col=\"Species\")\n",
    "        \n",
    "    dfs = []\n",
    "    rmsite = []\n",
    "    comment_string = f\"# UEA/FJZ data for {species}\\n\"\n",
    "    comment_string += f\"# Created by {getpass.getuser()} on {datetime.now()}\\n\"\n",
    "    comment_string += f\"# Contact data owners before use \\n\"\n",
    "    comment_string += f\"# This file contains data from the following sites/instruments: \\n\"\n",
    "    comment_string += \"#===================================================\\n\"\n",
    "\n",
    "    for site in sites.keys():\n",
    "        \n",
    "\n",
    "        df_site, comment_site = laube_sites(species, site)\n",
    "\n",
    "\n",
    "        if df_site is not None:\n",
    "            dfs.append(df_site)\n",
    "            comment_string += comment_site\n",
    "        else:\n",
    "            rmsite = rmsite + [site]\n",
    "\n",
    "    for rms in rmsite:\n",
    "        sites.pop(rms)\n",
    "\n",
    "    if len(dfs) == 0:\n",
    "        print(\"No data found\")\n",
    "\n",
    "    for bi in range(3,-1, -1):\n",
    "        if bi not in sites.values():\n",
    "            df_empty = dfs[0].copy() #\n",
    "            df_empty.loc[:] = np.nan\n",
    "            # dfs.append(df_empty)\n",
    "            # sites[f\"AA{bi}\"] = bi\n",
    "            dfs.insert(0, df_empty)\n",
    "            sites = {**{f\"XX{bi}\" : bi}, **sites}\n",
    "\n",
    "    # Find units\n",
    "    units = [df.xs(\"mf\", level=\"var\", axis=1).columns.get_level_values(\"unit\").values[0] for df in dfs]\n",
    "    if len(set(units)) != 1:\n",
    "        raise(f\"ERROR: Units don't match: {units}\")\n",
    "\n",
    "    # Find scales\n",
    "    scales = [df.xs(\"mf\", level=\"var\", axis=1).columns.get_level_values(\"scale\").values[0] for df in dfs]\n",
    "    if len(set(scales)) != 1:\n",
    "        raise(f\"ERROR: Units don't match: {scales}\")\n",
    "\n",
    "    # Concatenate and average numeric data\n",
    "    df_concat = pd.concat([df.xs(units[0], level=\"unit\", axis=1) for df in dfs], \n",
    "                        axis=1, keys=[(site, box) for site, box in sites.items()], names=[\"site\", \"box\"])\n",
    "    df_grouped = df_concat.groupby(by=[\"var\", \"box\", \"scale\"], axis=1).mean()\n",
    "\n",
    "    # Drop scale level\n",
    "    df_grouped = df_grouped.droplevel(\"scale\", axis=1)\n",
    "\n",
    "    # Collect instrument data\n",
    "    df_instrument_concat = pd.concat([df.xs(\"instrument\", level=\"var\", axis=1) for df in dfs], \n",
    "                                    axis=1, keys=[(site, box) for site, box in sites.items()], names=[\"site\", \"box\"])\n",
    "\n",
    "\n",
    "    instrument_list = pd.DataFrame(\n",
    "                            columns=pd.MultiIndex.from_tuples(((\"instruments\", 0),\n",
    "                                                                (\"instruments\", 1),\n",
    "                                                                (\"instruments\", 2),\n",
    "                                                                (\"instruments\", 3)), names=[\"var\", \"box\"]),\n",
    "                            index=df_grouped.index)#, dtype=pd.StringDtype())\n",
    "\n",
    "    for bi in range(4):\n",
    "        df_instrument_concat_bi = df_instrument_concat.xs(bi, level=\"box\", axis=1)\n",
    "        instrument_list.iloc[:, bi] = df_instrument_concat_bi.iloc[:, 0]\n",
    "        for sitei in range(len(df_instrument_concat_bi.columns))[1:]:\n",
    "            instrument_list.iloc[:, bi] = instrument_list.iloc[:, bi].str.cat(df_instrument_concat_bi.iloc[:,sitei],\n",
    "                                                                                sep=\"|\",\n",
    "                                                                                na_rep=\"\")\n",
    "\n",
    "    # Collect sites\n",
    "    site_list = pd.DataFrame(\n",
    "                            columns=pd.MultiIndex.from_tuples(((\"sites\", 0),\n",
    "                                                                (\"sites\", 1),\n",
    "                                                                (\"sites\", 2),\n",
    "                                                                (\"sites\", 3)), names=[\"var\", \"box\"]),\n",
    "                            index=df_grouped.index)#, dtype=pd.StringDtype())\n",
    "\n",
    "    for i in df_concat.index:\n",
    "        dfi = df_concat.loc[i].dropna()\n",
    "        if len(dfi) == 0:\n",
    "            site_list.loc[i] = [\"\", \"\", \"\", \"\"]\n",
    "        else:\n",
    "            site_row = []\n",
    "            for bi in range(4):\n",
    "                if bi in dfi.index.get_level_values(\"box\"):\n",
    "                    site_set = set(dfi.xs(bi, level=\"box\").index.get_level_values(\"site\"))\n",
    "                    if len(site_set) == 0:\n",
    "                        site_row.append(\"\")\n",
    "                    else:\n",
    "                        site_row.append(\"|\".join(site_set))\n",
    "                else:\n",
    "                    site_row.append(\"\")\n",
    "            site_list.loc[i] = site_row\n",
    "\n",
    "    # Put measurements, sites and instruments together into one dataframe\n",
    "    df_grouped = pd.concat([df_grouped, site_list, instrument_list], axis=1)\n",
    "\n",
    "    # Add a repeatability\n",
    "    df_grouped[\"mf_variability\"] = np.sqrt(df_grouped[\"mf_variability\"]**2 + (df_grouped[\"mf\"]*repeatability)**2)\n",
    "\n",
    "    # Append site and units\n",
    "    comment_string += f\"# SCALE: {scales[0]}\\n# UNITS: {units[0]}\\n\"\n",
    "\n",
    "    # If no output directory given, default to data folder\n",
    "    if not output_directory:\n",
    "        #output_directory = Path(__file__).parent.parent / \"data\" / species / \"inputs\"\n",
    "        output_directory = f\"/user/home/lw13938/work/py12box_laube/data/{species}/inputs/\"\n",
    "    # If output directories don't exist, create them\n",
    "    if not Path(output_directory).exists():\n",
    "        if not Path(output_directory).parent.exists():\n",
    "            print(f\"... creating directory {Path(output_directory).parent}\")\n",
    "            Path(output_directory).parent.mkdir()\n",
    "        print(f\"... creating directory {output_directory}\")\n",
    "        Path(output_directory).mkdir()\n",
    "        \n",
    "    with open(Path(output_directory) / f\"{species}_obs_laube.csv\", 'w') as fout:\n",
    "        fout.write(comment_string)\n",
    "        df_grouped.to_csv(fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1890cd75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12box",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
